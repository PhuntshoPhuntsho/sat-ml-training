{
  
    
        "post0": {
            "title": "Crop type mapping with deep learning",
            "content": "A guide for using deep-learning based semantic segmentation to map crop types in satellite imagery. The AOI we will be working with is located in South Africa. We will use data from the 2019 Zindi Farm Pin Crop Detection Challenge and an abridged pipeline from Sinergise&#39;s eo-flow. The architecture we will use is the TensorFlow based TFCN. . author: Lilly Thomas | categories: [python, deep learning, machine learning, segmentation, classification, tensorflow] | . Install eo-flow . !pip install git+https://github.com/sentinel-hub/eo-flow . Download data . Make an account on Zindi and proceed to https://zindi.africa/competitions/farm-pin-crop-detection-challenge/data to download the training and testing shapefiles: train.zip and test.zip . Import required libraries . import os # Jupyter notebook related %reload_ext autoreload %autoreload 2 %matplotlib inline %pylab inline # Basics of Python data handling and visualization import numpy as np import matplotlib as mpl import matplotlib.pyplot as plt import matplotlib.gridspec as gridspec from mpl_toolkits.axes_grid1 import make_axes_locatable import pandas as pd from shapely.geometry import Polygon # Basics of GIS import geopandas as gpd # The core of this example from eolearn.core import EOTask, EOPatch, LinearWorkflow, FeatureType, OverwritePermission, LoadFromDisk, SaveToDisk from eolearn.io import S2L1CWCSInput, ExportToTiff from eolearn.mask import AddCloudMaskTask, get_s2_pixel_cloud_detector, AddValidDataMaskTask from eolearn.geometry import VectorToRaster, PointSamplingTask, ErosionTask from eolearn.features import LinearInterpolation, SimpleFilterTask from sentinelhub import BBoxSplitter, BBox, CRS, CustomUrlParam # Machine learning import lightgbm as lgb from sklearn.externals import joblib from sklearn import metrics from sklearn import preprocessing # Misc import pickle import sys import os import datetime import itertools from tqdm import tqdm_notebook as tqdm import enum . Preprocess data . 1) Generate convex hull geometries enveloping the training and testing shapefiles, to serve as AOI geometries used when generating EOPatches with Sentinel 2 imagery. . 2) Split the AOI into smaller tiles . 3) Fill EOPatches with data, to include: . L1C list of select bands [B02, B03, B04, B08, B11, B12], corresponding to [B, G, R, NIR, SWIR1, SWIR2] wavelengths. | Cloud probability map and cloud mask from SentinelHub | NDVI, NDWI, euclidean NORM information, which we will calculate | A mask of pixel validity, derived from the acquired Senitnel data and cloud coverage information. We define a valid pixel if its metadata: IS_DATA == True, CLOUD_MASK == 0 (1 indicates that pixel was identified to be occluded by cloud) | . Import eo-flow modules . import tensorflow as tf import json from eoflow.models import TFCNModel from eoflow.input.eopatch import eopatch_dataset from eoflow.input.operations import augment_data, cache_dataset, extract_subpatches from eoflow.utils import create_dirs . Convert EOPatch data to tfrecords . tfrecord is TensorFlow&#39;s dataset format optimized for ML workflows . Augment the data . Horizontal and vertical flips . Configure the model hyperparameters . To include: . learning rate | number of classes | loss | metrics | number of iterations and/or epochs (training cycles) | . Train model . Predict with the trained model . Evaluate the trained model . We will calculate Intersection over Union as a measure for the quality of our model. . Visualize predicted crop type maps .",
            "url": "https://developmentseed.github.io/sat-ml-training/2020/07/28/croptype_deeplearning.html",
            "relUrl": "/2020/07/28/croptype_deeplearning.html",
            "date": " • Jul 28, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "LightGBM  for Crop Type and Land Classification",
            "content": "#install python packages to run this notebook !pip install -q rasterio rasterstats geopandas treeinterpreter lightgbm . import geopandas as gpd import matplotlib.pyplot as plt import numpy as np import lightgbm as lgb import rasterio import rasterstats from sklearn.metrics import confusion_matrix from sklearn.model_selection import train_test_split from os import path as op import pickle . # Mount drive to google colab # from google.colab import drive # drive.mount(&#39;/content/drive&#39;, force_remount=True) # root_dir = &quot;/content/drive/My Drive&quot; . Random Forest Model for Crop Type and Land Classification . Using data created by SERVIR East Africa, RCMRD, and FEWSNET, we demonstrate how to train a LightGBM classifier over Trans Nzoia county, Kenya. . # read in training data training_vectors = gpd.read_file(op.join(root_dir, &#39;training_data.geojson&#39;)) training_vectors.head() . name description geometry . 0 Shadow | None | MULTIPOLYGON (((34.83383 1.18204, 34.83577 1.1... | . 1 Forestland | None | MULTIPOLYGON (((35.30961 1.01328, 35.30964 1.0... | . 2 Maize | early reproductive | MULTIPOLYGON (((34.90904 1.09515, 34.90907 1.0... | . 3 Sugarcane | no change..maize farm on the right and far lef... | MULTIPOLYGON (((34.90750 1.08934, 34.90753 1.0... | . 4 Maize | reproductive good crop | MULTIPOLYGON (((34.87144 0.82953, 34.87147 0.8... | . # find all unique values of training data names to use as classes classes = np.unique(training_vectors.name) # classes = np.array(sorted(training_vectors.name.unique())) classes . array([&#39;Built&#39;, &#39;Cloud&#39;, &#39;Fallow&#39;, &#39;Forestland&#39;, &#39;Grassland&#39;, &#39;Maize&#39;, &#39;Shadow&#39;, &#39;Sugarcane&#39;, &#39;Sunflower&#39;, &#39;Waterbody&#39;], dtype=object) . # create a dictionary to convert class names into integers for modeling class_dict = dict(zip(classes, range(len(classes)))) class_dict . {&#39;Built&#39;: 0, &#39;Cloud&#39;: 1, &#39;Fallow&#39;: 2, &#39;Forestland&#39;: 3, &#39;Grassland&#39;: 4, &#39;Maize&#39;: 5, &#39;Shadow&#39;: 6, &#39;Sugarcane&#39;: 7, &#39;Sunflower&#39;: 8, &#39;Waterbody&#39;: 9} . %%time # this larger cell reads data from a raster file for each training vector import rasterio from rasterio.features import rasterize from rasterstats.io import bounds_window # raster information raster_file = op.join(root_dir, &#39;Trans_nzoia_2019_05-02.tif&#39;) bands = 6 # a custom function for getting each value from the raster def all_values(x): return x # this larger cell reads data from a raster file for each training vector X_raw = [] y_raw = [] with rasterio.open(raster_file, &#39;r&#39;) as src: for (label, geom) in zip(training_vectors.name, training_vectors.geometry): # read the raster data matching the geometry bounds window = bounds_window(geom.bounds, src.transform) # store our window information window_affine = src.window_transform(window) fsrc = src.read(window=window) # rasterize the (non-buffered) geometry into the larger shape and affine mask = rasterize( [(geom, 1)], out_shape=fsrc.shape[1:], transform=window_affine, fill=0, dtype=&#39;uint8&#39;, all_touched=True ).astype(bool) # for each label pixel (places where the mask is true)... label_pixels = np.argwhere(mask) for (row, col) in label_pixels: # add a pixel of data to X data = fsrc[:,row,col] one_x = np.nan_to_num(data, nan=1e-3) X_raw.append(one_x) # add the label to y y_raw.append(class_dict[label]) . CPU times: user 13.2 s, sys: 457 ms, total: 13.6 s Wall time: 20.4 s . # convert the training data lists into the appropriate shape and format for scikit-learn X = np.array(X_raw) y = np.array(y_raw) (X.shape, y.shape) . ((160461, 6), (160461,)) . # (optional) add extra band indices # helper function for calculating ND*I indices (bands in the final dimension) def band_index(arr, a, b): return np.expand_dims((arr[..., a] - arr[..., b]) / (arr[..., a] + arr[..., b]), axis=1) ndvi = band_index(X, 3, 2) ndwi = band_index(X, 1, 3) X = np.concatenate([X, ndvi, ndwi], axis=1) X.shape . (160461, 8) . # split the data into test and train sets X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) . # calculate class weights to allow for training on inbalanced training samples labels, counts = np.unique(y_train, return_counts=True) class_weight_dict = dict(zip(labels, 1 / counts)) class_weight_dict . {0: 0.00046882325363338024, 1: 0.001597444089456869, 2: 0.0004928536224741252, 3: 1.970093973482535e-05, 4: 0.000819000819000819, 5: 1.5704257424187697e-05, 6: 0.0002473410833539451, 7: 0.0002824858757062147, 8: 0.05263157894736842, 9: 0.003115264797507788} . %%time # initialize a lightgbm lgbm = lgb.LGBMClassifier( objective=&#39;multiclass&#39;, class_weight = class_weight_dict, num_class = len(class_dict), metric = &#39;multi_logloss&#39;) . CPU times: user 79 µs, sys: 5 µs, total: 84 µs Wall time: 90.4 µs . # fit the model to the data (training) lgbm.fit(X_train, y_train) . LGBMClassifier(boosting_type=&#39;gbdt&#39;, class_weight={0: 0.00046882325363338024, 1: 0.001597444089456869, 2: 0.0004928536224741252, 3: 1.970093973482535e-05, 4: 0.000819000819000819, 5: 1.5704257424187697e-05, 6: 0.0002473410833539451, 7: 0.0002824858757062147, 8: 0.05263157894736842, 9: 0.003115264797507788}, colsample_bytree=1.0, importance_type=&#39;split&#39;, learning_rate=0.1, max_depth=-1, metric=&#39;multi_logloss&#39;, min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_class=10, num_leaves=31, objective=&#39;multiclass&#39;, random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0, subsample_for_bin=200000, subsample_freq=0) . # predict on X_test to evaluate the model preds = lgbm.predict(X_test) cm = confusion_matrix(y_test, preds, labels=labels) . model_name = &#39;light_gbm.sav&#39; pickle.dump(lgbm, open(op.join(root_dir, model_name), &#39;wb&#39;)) . # plot the confusion matrix %matplotlib inline cm = cm.astype(&#39;float&#39;) / cm.sum(axis=1)[:, np.newaxis] fig, ax = plt.subplots(figsize=(10, 10)) im = ax.imshow(cm, interpolation=&#39;nearest&#39;, cmap=plt.cm.Blues) ax.figure.colorbar(im, ax=ax) # We want to show all ticks... ax.set(xticks=np.arange(cm.shape[1]), yticks=np.arange(cm.shape[0]), # ... and label them with the respective list entries xticklabels=classes, yticklabels=classes, title=&#39;Normalized Confusion Matrix&#39;, ylabel=&#39;True label&#39;, xlabel=&#39;Predicted label&#39;) # Rotate the tick labels and set their alignment. plt.setp(ax.get_xticklabels(), rotation=45, ha=&quot;right&quot;, rotation_mode=&quot;anchor&quot;) # Loop over data dimensions and create text annotations. fmt = &#39;.2f&#39; thresh = cm.max() / 2. for i in range(cm.shape[0]): for j in range(cm.shape[1]): ax.text(j, i, format(cm[i, j], fmt), ha=&quot;center&quot;, va=&quot;center&quot;, color=&quot;white&quot; if cm[i, j] &gt; thresh else &quot;black&quot;) fig.tight_layout() . Generate predictions over the full image . # if want to use the pretrained model for new imagery # helper function for calculating ND*I indices (bands in the final dimension) # match the pretrained model weight with the saved model above model_name = &#39;light_gbm.sav&#39; def band_index(arr, a, b): return np.expand_dims((arr[..., a] - arr[..., b]) / (arr[..., a] + arr[..., b]), axis=1) lgbm = pickle.load(open(op.join(root_dir, model_name), &#39;rb&#39;)) . lgbm . LGBMClassifier(boosting_type=&#39;gbdt&#39;, class_weight={0: 0.00046882325363338024, 1: 0.001597444089456869, 2: 0.0004928536224741252, 3: 1.970093973482535e-05, 4: 0.000819000819000819, 5: 1.5704257424187697e-05, 6: 0.0002473410833539451, 7: 0.0002824858757062147, 8: 0.05263157894736842, 9: 0.003115264797507788}, colsample_bytree=1.0, importance_type=&#39;split&#39;, learning_rate=0.1, max_depth=-1, metric=&#39;multi_logloss&#39;, min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_class=10, num_leaves=31, objective=&#39;multiclass&#39;, random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0, subsample_for_bin=200000, subsample_freq=0) . # src.close() # dst.close() . # if want to use the pretrained model for new imagery # The pretrained model is called &quot;random_forest.sav&quot; # helper function for calculating ND*I indices (bands in the final dimension) # open connections to our input and output images # new_image = op.join(root_dir, &#39;Trans_nzoia_2019_10-04.tif&#39;) new_image = raster_file output_image = op.join(root_dir, &quot;lgbm_classification.tif&quot;) src = rasterio.open(new_image, &#39;r&#39;) profile = src.profile profile.update( dtype=rasterio.uint8, count=1, ) dst = rasterio.open(output_image, &#39;w&#39;, **profile) # perform prediction on each small image patch to minimize required memory patch_size = 500 for i in range((src.shape[0] // patch_size) + 1): for j in range((src.shape[1] // patch_size) + 1): # define the pixels to read (and write) window = rasterio.windows.Window( j * patch_size, i * patch_size, # don&#39;t read past the image bounds min(patch_size, src.shape[1] - j * patch_size), min(patch_size, src.shape[0] - i * patch_size) ) data = src.read(window=window) # read the image into the proper format, adding indices if necessary img_swp = np.moveaxis(data, 0, 2) img_flat = img_swp.reshape(-1, img_swp.shape[-1]) img_ndvi = band_index(img_flat, 3, 2) img_ndwi = band_index(img_flat, 1, 3) img_w_ind = np.concatenate([img_flat, img_ndvi, img_ndwi], axis=1) # remove no data values, store the indices for later use # a later cell makes the assumption that all bands have identical no-data value arrangements m = np.ma.masked_invalid(img_w_ind) to_predict = img_w_ind[~m.mask].reshape(-1, img_w_ind.shape[-1]) # predict if not len(to_predict): continue img_preds = lgbm.predict(to_predict) # add the prediction back to the valid pixels (using only the first band of the mask to decide on validity) # resize to the original image dimensions output = np.zeros(img_flat.shape[0]) output[~m.mask[:,0]] = img_preds.flatten() output = output.reshape(*img_swp.shape[:-1]) # create our final mask mask = (~m.mask[:,0]).reshape(*img_swp.shape[:-1]) # write to the final file dst.write(output.astype(rasterio.uint8), 1, window=window) dst.write_mask(mask, window=window) # write to the final file dst.write(output.astype(rasterio.uint8), 1, window=window) dst.write_mask(mask, window=window) src.close() dst.close() .",
            "url": "https://developmentseed.github.io/sat-ml-training/2020/02/24/LightGBM_cropmapping.html",
            "relUrl": "/2020/02/24/LightGBM_cropmapping.html",
            "date": " • Feb 24, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Random Forest Model for Crop Type and Land Classification",
            "content": "from os import path as op import pickle import geopandas as gpd import matplotlib.pyplot as plt import numpy as np import rasterio from rasterio.features import rasterize from rasterstats.io import bounds_window import rasterstats from sklearn.metrics import confusion_matrix from sklearn.model_selection import train_test_split from sklearn.ensemble import RandomForestClassifier from treeinterpreter import treeinterpreter as ti . Label data preparation . TODOs . Add training dataset sourcing, creations . # read in training data polygons that created as geojson training_vectors = gpd.read_file(&#39;training_data.geojson&#39;) training_vectors.head() . name description geometry . 0 Shadow | None | MULTIPOLYGON (((34.83383 1.18204, 34.83577 1.1... | . 1 Forestland | None | MULTIPOLYGON (((35.30961 1.01328, 35.30964 1.0... | . 2 Maize | early reproductive | MULTIPOLYGON (((34.90904 1.09515, 34.90907 1.0... | . 3 Sugarcane | no change..maize farm on the right and far lef... | MULTIPOLYGON (((34.90750 1.08934, 34.90753 1.0... | . 4 Maize | reproductive good crop | MULTIPOLYGON (((34.87144 0.82953, 34.87147 0.8... | . # find all unique values of training data names to use as classes classes = np.unique(training_vectors.name) classes . array([&#39;Built&#39;, &#39;Cloud&#39;, &#39;Fallow&#39;, &#39;Forestland&#39;, &#39;Grassland&#39;, &#39;Maize&#39;, &#39;Shadow&#39;, &#39;Sugarcane&#39;, &#39;Sunflower&#39;, &#39;Waterbody&#39;], dtype=object) . # create a dictionary to convert class names into integers for modeling class_dict = dict(zip(classes, range(len(classes)))) class_dict . {&#39;Built&#39;: 0, &#39;Cloud&#39;: 1, &#39;Fallow&#39;: 2, &#39;Forestland&#39;: 3, &#39;Grassland&#39;: 4, &#39;Maize&#39;: 5, &#39;Shadow&#39;: 6, &#39;Sugarcane&#39;: 7, &#39;Sunflower&#39;: 8, &#39;Waterbody&#39;: 9} . Reading COG from AWS . TODOs How to read Sentinel-2 from AWS public S3. . # raster information raster_file = &#39;Trans_nzoia_2019_05-02.tif&#39; . Model training . # a custom function for getting each value from the raster def all_values(x): return x # this larger cell reads data from a raster file for each training vector X_raw = [] y_raw = [] with rasterio.open(raster_file, &#39;r&#39;) as src: for (label, geom) in zip(training_vectors.name, training_vectors.geometry): # read the raster data matching the geometry bounds window = bounds_window(geom.bounds, src.transform) # store our window information window_affine = src.window_transform(window) fsrc = src.read(window=window) # rasterize the geometry into the larger shape and affine mask = rasterize( [(geom, 1)], out_shape=fsrc.shape[1:], transform=window_affine, fill=0, dtype=&#39;uint8&#39;, all_touched=True ).astype(bool) # for each label pixel (places where the mask is true) label_pixels = np.argwhere(mask) for (row, col) in label_pixels: # add a pixel of data to X data = fsrc[:,row,col] one_x = np.nan_to_num(data, nan=1e-3) X_raw.append(one_x) # add the label to y y_raw.append(class_dict[label]) . # convert the training data lists into the appropriate numpy array shape and format for scikit-learn X = np.array(X_raw) y = np.array(y_raw) (X.shape, y.shape) . ((160461, 6), (160461,)) . # helper function for calculating ND*I indices (bands in the final dimension) def band_index(arr, a, b): return np.expand_dims((arr[..., a] - arr[..., b]) / (arr[..., a] + arr[..., b]), axis=1) ndvi = band_index(X, 3, 2) ndwi = band_index(X, 1, 3) X = np.concatenate([X, ndvi, ndwi], axis=1) X.shape . (160461, 8) . # split the data into test and train sets X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) . # calculate class weights to allow for training on inbalanced training samples labels, counts = np.unique(y_train, return_counts=True) class_weight_dict = dict(zip(labels, 1 / counts)) class_weight_dict . {0: 0.00046882325363338024, 1: 0.001597444089456869, 2: 0.0004928536224741252, 3: 1.970093973482535e-05, 4: 0.000819000819000819, 5: 1.5704257424187697e-05, 6: 0.0002473410833539451, 7: 0.0002824858757062147, 8: 0.05263157894736842, 9: 0.003115264797507788} . # initialize a RandomForestClassifier clf = RandomForestClassifier( n_estimators=200, class_weight=class_weight_dict, max_depth=6, n_jobs=-1, verbose=1, random_state=0) . # fit the model to the data (training) clf.fit(X, y) . [Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers. [Parallel(n_jobs=-1)]: Done 46 tasks | elapsed: 5.3s [Parallel(n_jobs=-1)]: Done 196 tasks | elapsed: 22.1s [Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed: 22.6s finished . RandomForestClassifier(bootstrap=True, class_weight={0: 0.00046882325363338024, 1: 0.001597444089456869, 2: 0.0004928536224741252, 3: 1.970093973482535e-05, 4: 0.000819000819000819, 5: 1.5704257424187697e-05, 6: 0.0002473410833539451, 7: 0.0002824858757062147, 8: 0.05263157894736842, 9: 0.003115264797507788}, criterion=&#39;gini&#39;, max_depth=6, max_features=&#39;auto&#39;, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1, oob_score=False, random_state=0, verbose=1, warm_start=False) . # predict on X_test to evaluate the model preds = clf.predict(X_test) cm = confusion_matrix(y_test, preds, labels=labels) . [Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers. [Parallel(n_jobs=2)]: Done 46 tasks | elapsed: 0.1s [Parallel(n_jobs=2)]: Done 196 tasks | elapsed: 0.5s [Parallel(n_jobs=2)]: Done 200 out of 200 | elapsed: 0.5s finished . # (optional) save the trained model as pickle file model_name = &#39;random_forest.sav&#39; with open(model_name, &#39;wb&#39;) as modelfile: pickle.dump(clf, modelfile) . # plot the confusion matrix %matplotlib inline cm = cm.astype(&#39;float&#39;) / cm.sum(axis=1)[:, np.newaxis] fig, ax = plt.subplots(figsize=(10, 10)) im = ax.imshow(cm, interpolation=&#39;nearest&#39;, cmap=plt.cm.Blues) ax.figure.colorbar(im, ax=ax) # We want to show all ticks... ax.set(xticks=np.arange(cm.shape[1]), yticks=np.arange(cm.shape[0]), # ... and label them with the respective list entries xticklabels=classes, yticklabels=classes, title=&#39;Normalized Confusion Matrix&#39;, ylabel=&#39;True label&#39;, xlabel=&#39;Predicted label&#39;) # Rotate the tick labels and set their alignment. plt.setp(ax.get_xticklabels(), rotation=45, ha=&quot;right&quot;, rotation_mode=&quot;anchor&quot;) # Loop over data dimensions and create text annotations. fmt = &#39;.2f&#39; thresh = cm.max() / 2. for i in range(cm.shape[0]): for j in range(cm.shape[1]): ax.text(j, i, format(cm[i, j], fmt), ha=&quot;center&quot;, va=&quot;center&quot;, color=&quot;white&quot; if cm[i, j] &gt; thresh else &quot;black&quot;) fig.tight_layout() . # predict again with the tree interpreter to see how much each band contributes to the classification sample = 100 prediction, bias, contributions = ti.predict(clf, X_test[:sample]) c = np.sum(contributions, axis=0) . # plot the contributions band_names = [&#39;Blue&#39;, &#39;Green&#39;, &#39;Red&#39;, &#39;NIR&#39;, &#39;SWIR1&#39;, &#39;SWIR2&#39;, &#39;NDVI&#39;, &#39;NDWI&#39;] gdf = gpd.GeoDataFrame(c, columns=classes, index=band_names) gdf.style.background_gradient(cmap=&#39;viridis&#39;) . Built Cloud Fallow Forestland Grassland Maize Shadow Sugarcane Sunflower Waterbody . Blue -0.708147 | -0.450384 | -2.68955 | 5.93931 | -0.460897 | 0.36023 | -0.154207 | -0.481766 | -0.167871 | -1.18672 | . Green -1.09678 | -0.00350109 | -1.57525 | 2.95823 | -0.336196 | 1.36762 | 0.551725 | -0.218106 | -0.732232 | -0.915498 | . Red -1.90573 | -0.59379 | 0.277761 | 3.01317 | 0.223731 | 0.7112 | -0.249443 | -0.619405 | -0.683663 | -0.173831 | . NIR 0.0684765 | -0.196796 | -2.96226 | 2.66494 | -0.747003 | 1.36166 | 0.791034 | 0.479715 | -1.19875 | -0.261016 | . SWIR1 0.166388 | 0.0139419 | -1.05339 | 3.05759 | -0.538389 | 0.81744 | 0.452637 | 0.357217 | -0.771856 | -2.50158 | . SWIR2 -0.734541 | -0.460321 | 0.715332 | 2.85215 | -0.179285 | 0.235555 | -0.271136 | -0.406578 | -1.01603 | -0.735149 | . NDVI -0.919315 | -0.238332 | 2.18171 | 3.64759 | -0.992437 | 1.17432 | -0.263332 | -0.444098 | -2.37513 | -1.77098 | . NDWI 0.121986 | 0.0502156 | 0.987004 | 2.8981 | -1.07648 | 0.740517 | 0.576891 | -0.444139 | -2.01388 | -1.84022 | . Generate predictions over the full image . Using the trained RandomForestClassifier clf over a new satellite image that cover a larger geospatial location. . # in this case, we predict over the entire input image # (only small portions were used for training) new_image = raster_file output_image = &quot;classification.tif&quot; with rasterio.open(new_image, &#39;r&#39;) as src: profile = src.profile profile.update( dtype=rasterio.uint8, count=1, ) with rasterio.open(output_image, &#39;w&#39;, **profile) as dst: # perform prediction on each small image patch to minimize required memory patch_size = 500 for i in range((src.shape[0] // patch_size) + 1): for j in range((src.shape[1] // patch_size) + 1): # define the pixels to read (and write) with rasterio windows reading window = rasterio.windows.Window( j * patch_size, i * patch_size, # don&#39;t read past the image bounds min(patch_size, src.shape[1] - j * patch_size), min(patch_size, src.shape[0] - i * patch_size)) # read the image into the proper format data = src.read(window=window) # adding indices if necessary img_swp = np.moveaxis(data, 0, 2) img_flat = img_swp.reshape(-1, img_swp.shape[-1]) img_ndvi = norm_inds(img_flat, 3, 2) img_ndwi = norm_inds(img_flat, 1, 3) img_w_ind = np.concatenate([img_flat, img_ndvi, img_ndwi], axis=1) # remove no data values, store the indices for later use m = np.ma.masked_invalid(img_w_ind) to_predict = img_w_ind[~m.mask].reshape(-1, img_w_ind.shape[-1]) # skip empty inputs if not len(to_predict): continue # predict img_preds = clf.predict(to_predict) # add the prediction back to the valid pixels (using only the first band of the mask to decide on validity) # makes the assumption that all bands have identical no-data value arrangements output = np.zeros(img_flat.shape[0]) output[~m.mask[:, 0]] = img_preds.flatten() # resize to the original image dimensions output = output.reshape(*img_swp.shape[:-1]) # create our final mask mask = (~m.mask[:, 0]).reshape(*img_swp.shape[:-1]) # write to the final files dst.write(output.astype(rasterio.uint8), 1, window=window) dst.write_mask(mask, window=window) .",
            "url": "https://developmentseed.github.io/sat-ml-training/2020/02/23/Randomforest_cropmapping_with_COGs.html",
            "relUrl": "/2020/02/23/Randomforest_cropmapping_with_COGs.html",
            "date": " • Feb 23, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Machine learning (ML)",
            "content": "References: . Introduction to Statistical Learning https://faculty.marshall.usc.edu/gareth-james/ISL/ Example from book in Python Notebooks https://github.com/tdpetrou/Machine-Learning-Books-With-Python/tree/master/Introduction%20to%20Statistical%20Learning | Additional Examples from Python for Data Science https://jakevdp.github.io/PythonDataScienceHandbook/index.html #5.-Machine-Learning | . 1.2.1 Classic ML . RandomForest . Decision tree and RandomForest classifier in-depth or w/ sciki-learn | RandomForest classifier in LULC case (DS example) . Best practice of train, validation and test split; . | Dealing with class imbalance . | Optimize estimators and leaves setting . | Model parallel training and prediction . | Model evaluation; . | . | . LightGBM . LightGBM . Gradient boost; | . | LightGBM in crop type mapping case (DS example and SentinelHub eo-learn example) . Best practice of train, validation and test split; . | Dealing with class imbalance . | Hyperparameter tuning . | Model parallel training and prediction with CPU and GPU . | Model evaluation; . | . | . 1.2.2 Deep learning . TF dynamic UNet . Image classification, object detection | Semantic Segment and dynamic UNet | Dynamic UNet in LULC case (DS example) | . TensorFlow FCN . Tensorflow | Tensorflow FCN | Tensorflow FCN in LULC | .",
            "url": "https://developmentseed.github.io/sat-ml-training/python/background/2020/02/23/IntroMachineLearning.html",
            "relUrl": "/python/background/2020/02/23/IntroMachineLearning.html",
            "date": " • Feb 23, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Random Forest Model for Crop Type and Land Classification",
            "content": "from os import path as op import pickle import geopandas as gpd import matplotlib.pyplot as plt import numpy as np import rasterio from rasterio.features import rasterize from rasterstats.io import bounds_window import rasterstats from sklearn.metrics import confusion_matrix from sklearn.model_selection import train_test_split from sklearn.ensemble import RandomForestClassifier from treeinterpreter import treeinterpreter as ti . Label data preparation . TODOs . Add training dataset sourcing, creations . # read in training data polygons that created as geojson training_vectors = gpd.read_file(&#39;training_data.geojson&#39;) training_vectors.head() . name description geometry . 0 Shadow | None | MULTIPOLYGON (((34.83383 1.18204, 34.83577 1.1... | . 1 Forestland | None | MULTIPOLYGON (((35.30961 1.01328, 35.30964 1.0... | . 2 Maize | early reproductive | MULTIPOLYGON (((34.90904 1.09515, 34.90907 1.0... | . 3 Sugarcane | no change..maize farm on the right and far lef... | MULTIPOLYGON (((34.90750 1.08934, 34.90753 1.0... | . 4 Maize | reproductive good crop | MULTIPOLYGON (((34.87144 0.82953, 34.87147 0.8... | . Reading image from GEE . TODOs How to read Sentinel-2 from GEE . raster_file = &#39;/Trans_nzoia_2019_05-02.tif&#39; . Model training . # find all unique values of training data names to use as classes classes = np.unique(training_vectors.name) classes . array([&#39;Built&#39;, &#39;Cloud&#39;, &#39;Fallow&#39;, &#39;Forestland&#39;, &#39;Grassland&#39;, &#39;Maize&#39;, &#39;Shadow&#39;, &#39;Sugarcane&#39;, &#39;Sunflower&#39;, &#39;Waterbody&#39;], dtype=object) . # create a dictionary to convert class names into integers for modeling class_dict = dict(zip(classes, range(len(classes)))) class_dict . {&#39;Built&#39;: 0, &#39;Cloud&#39;: 1, &#39;Fallow&#39;: 2, &#39;Forestland&#39;: 3, &#39;Grassland&#39;: 4, &#39;Maize&#39;: 5, &#39;Shadow&#39;: 6, &#39;Sugarcane&#39;: 7, &#39;Sunflower&#39;: 8, &#39;Waterbody&#39;: 9} . # raster information # a custom function for getting each value from the raster def all_values(x): return x # this larger cell reads data from a raster file for each training vector X_raw = [] y_raw = [] with rasterio.open(raster_file, &#39;r&#39;) as src: for (label, geom) in zip(training_vectors.name, training_vectors.geometry): # read the raster data matching the geometry bounds window = bounds_window(geom.bounds, src.transform) # store our window information window_affine = src.window_transform(window) fsrc = src.read(window=window) # rasterize the geometry into the larger shape and affine mask = rasterize( [(geom, 1)], out_shape=fsrc.shape[1:], transform=window_affine, fill=0, dtype=&#39;uint8&#39;, all_touched=True ).astype(bool) # for each label pixel (places where the mask is true) label_pixels = np.argwhere(mask) for (row, col) in label_pixels: # add a pixel of data to X data = fsrc[:,row,col] one_x = np.nan_to_num(data, nan=1e-3) X_raw.append(one_x) # add the label to y y_raw.append(class_dict[label]) . # convert the training data lists into the appropriate numpy array shape and format for scikit-learn X = np.array(X_raw) y = np.array(y_raw) (X.shape, y.shape) . ((160461, 6), (160461,)) . # helper function for calculating ND*I indices (bands in the final dimension) def band_index(arr, a, b): return np.expand_dims((arr[..., a] - arr[..., b]) / (arr[..., a] + arr[..., b]), axis=1) ndvi = band_index(X, 3, 2) ndwi = band_index(X, 1, 3) X = np.concatenate([X, ndvi, ndwi], axis=1) X.shape . (160461, 8) . # split the data into test and train sets X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) . # calculate class weights to allow for training on inbalanced training samples labels, counts = np.unique(y_train, return_counts=True) class_weight_dict = dict(zip(labels, 1 / counts)) class_weight_dict . {0: 0.00046882325363338024, 1: 0.001597444089456869, 2: 0.0004928536224741252, 3: 1.970093973482535e-05, 4: 0.000819000819000819, 5: 1.5704257424187697e-05, 6: 0.0002473410833539451, 7: 0.0002824858757062147, 8: 0.05263157894736842, 9: 0.003115264797507788} . # initialize a RandomForestClassifier clf = RandomForestClassifier( n_estimators=200, class_weight=class_weight_dict, max_depth=6, n_jobs=-1, verbose=1, random_state=0) . # fit the model to the data (training) clf.fit(X, y) . [Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers. [Parallel(n_jobs=-1)]: Done 46 tasks | elapsed: 5.3s [Parallel(n_jobs=-1)]: Done 196 tasks | elapsed: 22.1s [Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed: 22.6s finished . RandomForestClassifier(bootstrap=True, class_weight={0: 0.00046882325363338024, 1: 0.001597444089456869, 2: 0.0004928536224741252, 3: 1.970093973482535e-05, 4: 0.000819000819000819, 5: 1.5704257424187697e-05, 6: 0.0002473410833539451, 7: 0.0002824858757062147, 8: 0.05263157894736842, 9: 0.003115264797507788}, criterion=&#39;gini&#39;, max_depth=6, max_features=&#39;auto&#39;, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1, oob_score=False, random_state=0, verbose=1, warm_start=False) . # predict on X_test to evaluate the model preds = clf.predict(X_test) cm = confusion_matrix(y_test, preds, labels=labels) . [Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers. [Parallel(n_jobs=2)]: Done 46 tasks | elapsed: 0.1s [Parallel(n_jobs=2)]: Done 196 tasks | elapsed: 0.5s [Parallel(n_jobs=2)]: Done 200 out of 200 | elapsed: 0.5s finished . # (optional) save the trained model as pickle file model_name = &#39;random_forest.sav&#39; with open(model_name, &#39;wb&#39;) as modelfile: pickle.dump(clf, modelfile) . # plot the confusion matrix %matplotlib inline cm = cm.astype(&#39;float&#39;) / cm.sum(axis=1)[:, np.newaxis] fig, ax = plt.subplots(figsize=(10, 10)) im = ax.imshow(cm, interpolation=&#39;nearest&#39;, cmap=plt.cm.Blues) ax.figure.colorbar(im, ax=ax) # We want to show all ticks... ax.set(xticks=np.arange(cm.shape[1]), yticks=np.arange(cm.shape[0]), # ... and label them with the respective list entries xticklabels=classes, yticklabels=classes, title=&#39;Normalized Confusion Matrix&#39;, ylabel=&#39;True label&#39;, xlabel=&#39;Predicted label&#39;) # Rotate the tick labels and set their alignment. plt.setp(ax.get_xticklabels(), rotation=45, ha=&quot;right&quot;, rotation_mode=&quot;anchor&quot;) # Loop over data dimensions and create text annotations. fmt = &#39;.2f&#39; thresh = cm.max() / 2. for i in range(cm.shape[0]): for j in range(cm.shape[1]): ax.text(j, i, format(cm[i, j], fmt), ha=&quot;center&quot;, va=&quot;center&quot;, color=&quot;white&quot; if cm[i, j] &gt; thresh else &quot;black&quot;) fig.tight_layout() . # predict again with the tree interpreter to see how much each band contributes to the classification sample = 100 prediction, bias, contributions = ti.predict(clf, X_test[:sample]) c = np.sum(contributions, axis=0) . # plot the contributions band_names = [&#39;Blue&#39;, &#39;Green&#39;, &#39;Red&#39;, &#39;NIR&#39;, &#39;SWIR1&#39;, &#39;SWIR2&#39;, &#39;NDVI&#39;, &#39;NDWI&#39;] gdf = gpd.GeoDataFrame(c, columns=classes, index=band_names) gdf.style.background_gradient(cmap=&#39;viridis&#39;) . Built Cloud Fallow Forestland Grassland Maize Shadow Sugarcane Sunflower Waterbody . Blue -0.708147 | -0.450384 | -2.68955 | 5.93931 | -0.460897 | 0.36023 | -0.154207 | -0.481766 | -0.167871 | -1.18672 | . Green -1.09678 | -0.00350109 | -1.57525 | 2.95823 | -0.336196 | 1.36762 | 0.551725 | -0.218106 | -0.732232 | -0.915498 | . Red -1.90573 | -0.59379 | 0.277761 | 3.01317 | 0.223731 | 0.7112 | -0.249443 | -0.619405 | -0.683663 | -0.173831 | . NIR 0.0684765 | -0.196796 | -2.96226 | 2.66494 | -0.747003 | 1.36166 | 0.791034 | 0.479715 | -1.19875 | -0.261016 | . SWIR1 0.166388 | 0.0139419 | -1.05339 | 3.05759 | -0.538389 | 0.81744 | 0.452637 | 0.357217 | -0.771856 | -2.50158 | . SWIR2 -0.734541 | -0.460321 | 0.715332 | 2.85215 | -0.179285 | 0.235555 | -0.271136 | -0.406578 | -1.01603 | -0.735149 | . NDVI -0.919315 | -0.238332 | 2.18171 | 3.64759 | -0.992437 | 1.17432 | -0.263332 | -0.444098 | -2.37513 | -1.77098 | . NDWI 0.121986 | 0.0502156 | 0.987004 | 2.8981 | -1.07648 | 0.740517 | 0.576891 | -0.444139 | -2.01388 | -1.84022 | . Generate predictions over the full image . Using the trained RandomForestClassifier clf over a new satellite image that cover a larger geospatial location. . # in this case, we predict over the entire input image # (only small portions were used for training) new_image = raster_file output_image = &quot;classification.tif&quot; with rasterio.open(new_image, &#39;r&#39;) as src: profile = src.profile profile.update( dtype=rasterio.uint8, count=1, ) with rasterio.open(output_image, &#39;w&#39;, **profile) as dst: # perform prediction on each small image patch to minimize required memory patch_size = 500 for i in range((src.shape[0] // patch_size) + 1): for j in range((src.shape[1] // patch_size) + 1): # define the pixels to read (and write) with rasterio windows reading window = rasterio.windows.Window( j * patch_size, i * patch_size, # don&#39;t read past the image bounds min(patch_size, src.shape[1] - j * patch_size), min(patch_size, src.shape[0] - i * patch_size)) # read the image into the proper format data = src.read(window=window) # adding indices if necessary img_swp = np.moveaxis(data, 0, 2) img_flat = img_swp.reshape(-1, img_swp.shape[-1]) img_ndvi = norm_inds(img_flat, 3, 2) img_ndwi = norm_inds(img_flat, 1, 3) img_w_ind = np.concatenate([img_flat, img_ndvi, img_ndwi], axis=1) # remove no data values, store the indices for later use m = np.ma.masked_invalid(img_w_ind) to_predict = img_w_ind[~m.mask].reshape(-1, img_w_ind.shape[-1]) # skip empty inputs if not len(to_predict): continue # predict img_preds = clf.predict(to_predict) # add the prediction back to the valid pixels (using only the first band of the mask to decide on validity) # makes the assumption that all bands have identical no-data value arrangements output = np.zeros(img_flat.shape[0]) output[~m.mask[:, 0]] = img_preds.flatten() # resize to the original image dimensions output = output.reshape(*img_swp.shape[:-1]) # create our final mask mask = (~m.mask[:, 0]).reshape(*img_swp.shape[:-1]) # write to the final files dst.write(output.astype(rasterio.uint8), 1, window=window) dst.write_mask(mask, window=window) .",
            "url": "https://developmentseed.github.io/sat-ml-training/2020/02/22/Randomforest_cropmapping-with_GEE.html",
            "relUrl": "/2020/02/22/Randomforest_cropmapping-with_GEE.html",
            "date": " • Feb 22, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "Geospatial Python",
            "content": "The following material covers the basics of using spatial data in python. The main goal is to become familiar with the libraries used, and to try a few examples of operations with vector, and raster data, including some basic visualizations. . The Main lessons come from AutoGIS . Vector Data . How to load and save spatial data with . [Geopandas](https://automating-gis-processes.github.io/site/notebooks/L2/geopandas-basics.html#Input-data:-Finnish-topographic-database) . | Data Manipulation . ([Geopandas](https://automating-gis-processes.github.io/site/notebooks/L2/geopandas-basics.html)) . **Projections | Geopandas/Shapely . | Intersects . | Bounding Box (BBOX) bounds . | Centroids centroid . | Filtering Data . Subsetting, to select records based on attributes use . the techniques from Pandas . | [Spatial . Join](https://automating-gis-processes.github.io/site/notebooks/L3/spatial-join.html) . | [Spatial . Aggregation](https://automating-gis-processes.github.io/site/notebooks/L4/geometric-operations.html#Aggregating-data) . | . | . | . Making Maps . Static, more examples | Dynamic | . Optional Bonus Material . Vector Input/Output(I/O) with Fiona | Using Spatial Indexes for faster analysis | . Raster . How to load and save data . Rasterio (Reading) | Rasterio (Writing) | . | Numpy Arrays (Rasters) . Clipping raster by AOI | Band Math (aka Map Algebra) | Sampling data from raster with a vector | . | . Making Maps . Static | Dynamic with Vector Data | . Additional References . Geopandas for vector geometry and attribute handling . | Shapely for vector geometry operations that Geopandas doesn’t do . | .",
            "url": "https://developmentseed.github.io/sat-ml-training/python/background/2020/02/22/GeospatialPython.html",
            "relUrl": "/python/background/2020/02/22/GeospatialPython.html",
            "date": " • Feb 22, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "Intro to Python",
            "content": "General python . An introduction or refresher for Python 3 Online Videos from Udemy AND/OR | Interactive lessons with examples and quizzes from CodeAcademy (Recommend all lessons except #10 on Classes) | . OR . https://github.com/jakevdp/WhirlwindTourOfPython | . Goals . Data types . Basic Types: Integers (Whole numbers), Floats (Numbers with decimals), Strings | Constructed Types: Lists, Dictionaries . Note: Dictionaries and the JSON file format are very similar in how they structure data. . | . | . | Looping (Program flow control) . Using looping to iterate over a set of items to repeat a process . Example: Loop over a list of items . | Example: Loop over list of files . | . | . | Calling functions . Importing libraries (aka modules, packages) | How to call a function | How to write a small function | . | . Additional References . Python Documentation https://docs.python.org/3/tutorial/index.html . | More tutorials https://docs.python-guide.org/intro/learning/ . | . Python for Data Science . Primary Source https://jakevdp.github.io/PythonDataScienceHandbook/index.html | Secondary Source https://datacarpentry.org/python-ecology-lesson/ | . Numpy . . Important: Understanding multidimensional data arrays as a data structure . Note: Numpy array data must all be of the same type (e.g. Integer, Float, etc…) . Lessons: . Introduction to NumPy . | Understanding Data Types in Python . | The Basics of NumPy Arrays . | Computation on NumPy Arrays: Universal Functions . | Aggregations: Min, Max, and Everything In Between . | . Pandas . . Important: Understanding data frames as a table (sheet), with data records as rows, and data attributes as columns. Each column can be a different data type . Lessons: . Introduction . | Importing and exporting CSV and JSON data sources . | Summarizing (aggregating) data . | Selecting relevant data records . | (Optional) More details . | . Plotting . . Important: Being able to visualize selections of data in a variety of standard plot types. Histogram, Bar, Line, Scatter Plot (XY) . Visualization with Matplotlib . | Simple Line Plots . | Scatter Plots . | Density and Contour Plots . | Histograms, Binnings, and Density . | .",
            "url": "https://developmentseed.github.io/sat-ml-training/python/background/2020/02/21/IntroPython.html",
            "relUrl": "/python/background/2020/02/21/IntroPython.html",
            "date": " • Feb 21, 2020"
        }
        
    
  
    
        ,"post7": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: main- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . #collapse-hide import pandas as pd import altair as alt . . ModuleNotFoundError Traceback (most recent call last) &lt;ipython-input-2-88b922e30289&gt; in &lt;module&gt; 1 #collapse-hide 2 import pandas as pd -&gt; 3 import altair as alt ModuleNotFoundError: No module named &#39;altair&#39; . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . #collapse-show cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # single-value selection over [Major_Genre, MPAA_Rating] pairs # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . # select a point for which to provide details-on-demand label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . # display table with pandas df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://developmentseed.github.io/sat-ml-training/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Material on this website is available under __ license. It was originally developed by Development Seed for the SERVIR program (NASA &amp; USAID). . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://developmentseed.github.io/sat-ml-training/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://developmentseed.github.io/sat-ml-training/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}
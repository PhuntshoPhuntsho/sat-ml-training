{
  
    
        "post0": {
            "title": "Crop type mapping with deep learning",
            "content": "The AOI we will be working with is located in South Africa. We will use data from the 2019 Zindi Farm Pin Crop Detection Challenge and an abridged pipeline from Sinergise&#39;s eo-flow. The architecture we will use is the TensorFlow based TFCN. . Install eo-flow . !pip install git+https://github.com/sentinel-hub/eo-flow . Download data . Make an account on Zindi and proceed to https://zindi.africa/competitions/farm-pin-crop-detection-challenge/data to download the training and testing shapefiles: train.zip and test.zip . Import required libraries . import os # Jupyter notebook related %reload_ext autoreload %autoreload 2 %matplotlib inline %pylab inline # Basics of Python data handling and visualization import numpy as np import matplotlib as mpl import matplotlib.pyplot as plt import matplotlib.gridspec as gridspec from mpl_toolkits.axes_grid1 import make_axes_locatable import pandas as pd from shapely.geometry import Polygon # Basics of GIS import geopandas as gpd # The core of this example from eolearn.core import EOTask, EOPatch, LinearWorkflow, FeatureType, OverwritePermission, LoadFromDisk, SaveToDisk from eolearn.io import S2L1CWCSInput, ExportToTiff from eolearn.mask import AddCloudMaskTask, get_s2_pixel_cloud_detector, AddValidDataMaskTask from eolearn.geometry import VectorToRaster, PointSamplingTask, ErosionTask from eolearn.features import LinearInterpolation, SimpleFilterTask from sentinelhub import BBoxSplitter, BBox, CRS, CustomUrlParam # Machine learning import lightgbm as lgb from sklearn.externals import joblib from sklearn import metrics from sklearn import preprocessing # Misc import pickle import sys import os import datetime import itertools from tqdm import tqdm_notebook as tqdm import enum . Preprocess data . 1) Generate convex hull geometries enveloping the training and testing shapefiles, to serve as AOI geometries used when generating EOPatches with Sentinel 2 imagery. . 2) Split the AOI into smaller tiles . 3) Fill EOPatches with data, to include: . L1C list of select bands [B02, B03, B04, B08, B11, B12], corresponding to [B, G, R, NIR, SWIR1, SWIR2] wavelengths. | Cloud probability map and cloud mask from SentinelHub | NDVI, NDWI, euclidean NORM information, which we will calculate | A mask of pixel validity, derived from the acquired Senitnel data and cloud coverage information. We define a valid pixel if its metadata: IS_DATA == True, CLOUD_MASK == 0 (1 indicates that pixel was identified to be occluded by cloud) | . Import eo-flow modules . import tensorflow as tf import json from eoflow.models import TFCNModel from eoflow.input.eopatch import eopatch_dataset from eoflow.input.operations import augment_data, cache_dataset, extract_subpatches from eoflow.utils import create_dirs . Convert EOPatch data to tfrecords . tfrecord is TensorFlow&#39;s dataset format optimized for ML workflows . Augment the data . Horizontal and vertical flips . Configure the model hyperparameters . To include: . learning rate | number of classes | loss | metrics | number of iterations and/or epochs (training cycles) | . Train model . Predict with the trained model . Evaluate the trained model . We will calculate Intersection over Union as a measure for the quality of our model. . Visualize predicted crop type maps .",
            "url": "https://developmentseed.github.io/sat-ml-training/python/deep%20learning/machine%20learning/segmentation/classification/tensorflow/2020/07/28/croptype_deeplearning.html",
            "relUrl": "/python/deep%20learning/machine%20learning/segmentation/classification/tensorflow/2020/07/28/croptype_deeplearning.html",
            "date": " • Jul 28, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "LightGBM  for Crop Type and Land Classification",
            "content": "This notebook teaches you to read satellite imagery (Sentinal-2) from AWS public S3 Buckets through AWS Public Data Program for crop type mapping. . #install python packages to run this notebook !pip install -q rasterio rasterstats geopandas treeinterpreter lightgbm . import geopandas as gpd import matplotlib.pyplot as plt import numpy as np import lightgbm as lgb import rasterio import rasterstats from sklearn.metrics import confusion_matrix from sklearn.model_selection import train_test_split from os import path as op import pickle . # Mount drive to google colab # from google.colab import drive # drive.mount(&#39;/content/drive&#39;, force_remount=True) # root_dir = &quot;/content/drive/My Drive&quot; . Random Forest Model for Crop Type and Land Classification . Using data created by SERVIR East Africa, RCMRD, and FEWSNET, we demonstrate how to train a LightGBM classifier over Trans Nzoia county, Kenya. . # read in training data training_vectors = gpd.read_file(op.join(root_dir, &#39;training_data.geojson&#39;)) training_vectors.head() . name description geometry . 0 Shadow | None | MULTIPOLYGON (((34.83383 1.18204, 34.83577 1.1... | . 1 Forestland | None | MULTIPOLYGON (((35.30961 1.01328, 35.30964 1.0... | . 2 Maize | early reproductive | MULTIPOLYGON (((34.90904 1.09515, 34.90907 1.0... | . 3 Sugarcane | no change..maize farm on the right and far lef... | MULTIPOLYGON (((34.90750 1.08934, 34.90753 1.0... | . 4 Maize | reproductive good crop | MULTIPOLYGON (((34.87144 0.82953, 34.87147 0.8... | . # find all unique values of training data names to use as classes classes = np.unique(training_vectors.name) # classes = np.array(sorted(training_vectors.name.unique())) classes . array([&#39;Built&#39;, &#39;Cloud&#39;, &#39;Fallow&#39;, &#39;Forestland&#39;, &#39;Grassland&#39;, &#39;Maize&#39;, &#39;Shadow&#39;, &#39;Sugarcane&#39;, &#39;Sunflower&#39;, &#39;Waterbody&#39;], dtype=object) . # create a dictionary to convert class names into integers for modeling class_dict = dict(zip(classes, range(len(classes)))) class_dict . {&#39;Built&#39;: 0, &#39;Cloud&#39;: 1, &#39;Fallow&#39;: 2, &#39;Forestland&#39;: 3, &#39;Grassland&#39;: 4, &#39;Maize&#39;: 5, &#39;Shadow&#39;: 6, &#39;Sugarcane&#39;: 7, &#39;Sunflower&#39;: 8, &#39;Waterbody&#39;: 9} . %%time # this larger cell reads data from a raster file for each training vector import rasterio from rasterio.features import rasterize from rasterstats.io import bounds_window # raster information raster_file = op.join(root_dir, &#39;Trans_nzoia_2019_05-02.tif&#39;) bands = 6 # a custom function for getting each value from the raster def all_values(x): return x # this larger cell reads data from a raster file for each training vector X_raw = [] y_raw = [] with rasterio.open(raster_file, &#39;r&#39;) as src: for (label, geom) in zip(training_vectors.name, training_vectors.geometry): # read the raster data matching the geometry bounds window = bounds_window(geom.bounds, src.transform) # store our window information window_affine = src.window_transform(window) fsrc = src.read(window=window) # rasterize the (non-buffered) geometry into the larger shape and affine mask = rasterize( [(geom, 1)], out_shape=fsrc.shape[1:], transform=window_affine, fill=0, dtype=&#39;uint8&#39;, all_touched=True ).astype(bool) # for each label pixel (places where the mask is true)... label_pixels = np.argwhere(mask) for (row, col) in label_pixels: # add a pixel of data to X data = fsrc[:,row,col] one_x = np.nan_to_num(data, nan=1e-3) X_raw.append(one_x) # add the label to y y_raw.append(class_dict[label]) . CPU times: user 13.2 s, sys: 457 ms, total: 13.6 s Wall time: 20.4 s . # convert the training data lists into the appropriate shape and format for scikit-learn X = np.array(X_raw) y = np.array(y_raw) (X.shape, y.shape) . ((160461, 6), (160461,)) . # (optional) add extra band indices # helper function for calculating ND*I indices (bands in the final dimension) def band_index(arr, a, b): return np.expand_dims((arr[..., a] - arr[..., b]) / (arr[..., a] + arr[..., b]), axis=1) ndvi = band_index(X, 3, 2) ndwi = band_index(X, 1, 3) X = np.concatenate([X, ndvi, ndwi], axis=1) X.shape . (160461, 8) . # split the data into test and train sets X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) . # calculate class weights to allow for training on inbalanced training samples labels, counts = np.unique(y_train, return_counts=True) class_weight_dict = dict(zip(labels, 1 / counts)) class_weight_dict . {0: 0.00046882325363338024, 1: 0.001597444089456869, 2: 0.0004928536224741252, 3: 1.970093973482535e-05, 4: 0.000819000819000819, 5: 1.5704257424187697e-05, 6: 0.0002473410833539451, 7: 0.0002824858757062147, 8: 0.05263157894736842, 9: 0.003115264797507788} . %%time # initialize a lightgbm lgbm = lgb.LGBMClassifier( objective=&#39;multiclass&#39;, class_weight = class_weight_dict, num_class = len(class_dict), metric = &#39;multi_logloss&#39;) . CPU times: user 79 µs, sys: 5 µs, total: 84 µs Wall time: 90.4 µs . # fit the model to the data (training) lgbm.fit(X_train, y_train) . LGBMClassifier(boosting_type=&#39;gbdt&#39;, class_weight={0: 0.00046882325363338024, 1: 0.001597444089456869, 2: 0.0004928536224741252, 3: 1.970093973482535e-05, 4: 0.000819000819000819, 5: 1.5704257424187697e-05, 6: 0.0002473410833539451, 7: 0.0002824858757062147, 8: 0.05263157894736842, 9: 0.003115264797507788}, colsample_bytree=1.0, importance_type=&#39;split&#39;, learning_rate=0.1, max_depth=-1, metric=&#39;multi_logloss&#39;, min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_class=10, num_leaves=31, objective=&#39;multiclass&#39;, random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0, subsample_for_bin=200000, subsample_freq=0) . # predict on X_test to evaluate the model preds = lgbm.predict(X_test) cm = confusion_matrix(y_test, preds, labels=labels) . model_name = &#39;light_gbm.sav&#39; pickle.dump(lgbm, open(op.join(root_dir, model_name), &#39;wb&#39;)) . # plot the confusion matrix %matplotlib inline cm = cm.astype(&#39;float&#39;) / cm.sum(axis=1)[:, np.newaxis] fig, ax = plt.subplots(figsize=(10, 10)) im = ax.imshow(cm, interpolation=&#39;nearest&#39;, cmap=plt.cm.Blues) ax.figure.colorbar(im, ax=ax) # We want to show all ticks... ax.set(xticks=np.arange(cm.shape[1]), yticks=np.arange(cm.shape[0]), # ... and label them with the respective list entries xticklabels=classes, yticklabels=classes, title=&#39;Normalized Confusion Matrix&#39;, ylabel=&#39;True label&#39;, xlabel=&#39;Predicted label&#39;) # Rotate the tick labels and set their alignment. plt.setp(ax.get_xticklabels(), rotation=45, ha=&quot;right&quot;, rotation_mode=&quot;anchor&quot;) # Loop over data dimensions and create text annotations. fmt = &#39;.2f&#39; thresh = cm.max() / 2. for i in range(cm.shape[0]): for j in range(cm.shape[1]): ax.text(j, i, format(cm[i, j], fmt), ha=&quot;center&quot;, va=&quot;center&quot;, color=&quot;white&quot; if cm[i, j] &gt; thresh else &quot;black&quot;) fig.tight_layout() . Generate predictions over the full image . # if want to use the pretrained model for new imagery # helper function for calculating ND*I indices (bands in the final dimension) # match the pretrained model weight with the saved model above model_name = &#39;light_gbm.sav&#39; def band_index(arr, a, b): return np.expand_dims((arr[..., a] - arr[..., b]) / (arr[..., a] + arr[..., b]), axis=1) lgbm = pickle.load(open(op.join(root_dir, model_name), &#39;rb&#39;)) . lgbm . LGBMClassifier(boosting_type=&#39;gbdt&#39;, class_weight={0: 0.00046882325363338024, 1: 0.001597444089456869, 2: 0.0004928536224741252, 3: 1.970093973482535e-05, 4: 0.000819000819000819, 5: 1.5704257424187697e-05, 6: 0.0002473410833539451, 7: 0.0002824858757062147, 8: 0.05263157894736842, 9: 0.003115264797507788}, colsample_bytree=1.0, importance_type=&#39;split&#39;, learning_rate=0.1, max_depth=-1, metric=&#39;multi_logloss&#39;, min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_class=10, num_leaves=31, objective=&#39;multiclass&#39;, random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0, subsample_for_bin=200000, subsample_freq=0) . # src.close() # dst.close() . # if want to use the pretrained model for new imagery # The pretrained model is called &quot;random_forest.sav&quot; # helper function for calculating ND*I indices (bands in the final dimension) # open connections to our input and output images # new_image = op.join(root_dir, &#39;Trans_nzoia_2019_10-04.tif&#39;) new_image = raster_file output_image = op.join(root_dir, &quot;lgbm_classification.tif&quot;) src = rasterio.open(new_image, &#39;r&#39;) profile = src.profile profile.update( dtype=rasterio.uint8, count=1, ) dst = rasterio.open(output_image, &#39;w&#39;, **profile) # perform prediction on each small image patch to minimize required memory patch_size = 500 for i in range((src.shape[0] // patch_size) + 1): for j in range((src.shape[1] // patch_size) + 1): # define the pixels to read (and write) window = rasterio.windows.Window( j * patch_size, i * patch_size, # don&#39;t read past the image bounds min(patch_size, src.shape[1] - j * patch_size), min(patch_size, src.shape[0] - i * patch_size) ) data = src.read(window=window) # read the image into the proper format, adding indices if necessary img_swp = np.moveaxis(data, 0, 2) img_flat = img_swp.reshape(-1, img_swp.shape[-1]) img_ndvi = band_index(img_flat, 3, 2) img_ndwi = band_index(img_flat, 1, 3) img_w_ind = np.concatenate([img_flat, img_ndvi, img_ndwi], axis=1) # remove no data values, store the indices for later use # a later cell makes the assumption that all bands have identical no-data value arrangements m = np.ma.masked_invalid(img_w_ind) to_predict = img_w_ind[~m.mask].reshape(-1, img_w_ind.shape[-1]) # predict if not len(to_predict): continue img_preds = lgbm.predict(to_predict) # add the prediction back to the valid pixels (using only the first band of the mask to decide on validity) # resize to the original image dimensions output = np.zeros(img_flat.shape[0]) output[~m.mask[:,0]] = img_preds.flatten() output = output.reshape(*img_swp.shape[:-1]) # create our final mask mask = (~m.mask[:,0]).reshape(*img_swp.shape[:-1]) # write to the final file dst.write(output.astype(rasterio.uint8), 1, window=window) dst.write_mask(mask, window=window) # write to the final file dst.write(output.astype(rasterio.uint8), 1, window=window) dst.write_mask(mask, window=window) src.close() dst.close() .",
            "url": "https://developmentseed.github.io/sat-ml-training/2020/02/24/LightGBM_cropmapping.html",
            "relUrl": "/2020/02/24/LightGBM_cropmapping.html",
            "date": " • Feb 24, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Random Forest Model for Crop Type and Land Classification",
            "content": "Using RandomForest Classifier for crop type mapping for SERVIR Sat ML training. This notebook showcase how we can read satellite imagery (Sentinal-2) from AWS public S3 through AWS Public Data Program for crop type mapping. . If you want to run this whole notebook on Google Colab, here is the link. . | If you would like to replicate the workflow with the same data on your local machine, please download the data from our shared Google Drive folder. . | . Besides mapping crop type with RandomForestClassifier, we also prepared notebooks that use LightGBM and SVM. . Find our notebook for LightGBM on Google Colab; | Find our notebook for SVM on Google Colab. | . from os import path as op import pickle import geopandas as gpd import matplotlib.pyplot as plt import numpy as np import rasterio from rasterio.features import rasterize from rasterstats.io import bounds_window import rasterstats from sklearn.metrics import confusion_matrix from sklearn.model_selection import train_test_split from sklearn.ensemble import RandomForestClassifier from treeinterpreter import treeinterpreter as ti . Label data preparation . TODOs . Add training dataset sourcing, creations . # read in training data polygons that created as geojson training_vectors = gpd.read_file(&#39;training_data.geojson&#39;) training_vectors.head() . name description geometry . 0 Shadow | None | MULTIPOLYGON (((34.83383 1.18204, 34.83577 1.1... | . 1 Forestland | None | MULTIPOLYGON (((35.30961 1.01328, 35.30964 1.0... | . 2 Maize | early reproductive | MULTIPOLYGON (((34.90904 1.09515, 34.90907 1.0... | . 3 Sugarcane | no change..maize farm on the right and far lef... | MULTIPOLYGON (((34.90750 1.08934, 34.90753 1.0... | . 4 Maize | reproductive good crop | MULTIPOLYGON (((34.87144 0.82953, 34.87147 0.8... | . # find all unique values of training data names to use as classes classes = np.unique(training_vectors.name) classes . array([&#39;Built&#39;, &#39;Cloud&#39;, &#39;Fallow&#39;, &#39;Forestland&#39;, &#39;Grassland&#39;, &#39;Maize&#39;, &#39;Shadow&#39;, &#39;Sugarcane&#39;, &#39;Sunflower&#39;, &#39;Waterbody&#39;], dtype=object) . # create a dictionary to convert class names into integers for modeling class_dict = dict(zip(classes, range(len(classes)))) class_dict . {&#39;Built&#39;: 0, &#39;Cloud&#39;: 1, &#39;Fallow&#39;: 2, &#39;Forestland&#39;: 3, &#39;Grassland&#39;: 4, &#39;Maize&#39;: 5, &#39;Shadow&#39;: 6, &#39;Sugarcane&#39;: 7, &#39;Sunflower&#39;: 8, &#39;Waterbody&#39;: 9} . Reading COG from AWS . TODOs How to read Sentinel-2 from AWS public S3. . # raster information raster_file = &#39;Trans_nzoia_2019_05-02.tif&#39; . Model training . # a custom function for getting each value from the raster def all_values(x): return x # this larger cell reads data from a raster file for each training vector X_raw = [] y_raw = [] with rasterio.open(raster_file, &#39;r&#39;) as src: for (label, geom) in zip(training_vectors.name, training_vectors.geometry): # read the raster data matching the geometry bounds window = bounds_window(geom.bounds, src.transform) # store our window information window_affine = src.window_transform(window) fsrc = src.read(window=window) # rasterize the geometry into the larger shape and affine mask = rasterize( [(geom, 1)], out_shape=fsrc.shape[1:], transform=window_affine, fill=0, dtype=&#39;uint8&#39;, all_touched=True ).astype(bool) # for each label pixel (places where the mask is true) label_pixels = np.argwhere(mask) for (row, col) in label_pixels: # add a pixel of data to X data = fsrc[:,row,col] one_x = np.nan_to_num(data, nan=1e-3) X_raw.append(one_x) # add the label to y y_raw.append(class_dict[label]) . # convert the training data lists into the appropriate numpy array shape and format for scikit-learn X = np.array(X_raw) y = np.array(y_raw) (X.shape, y.shape) . ((160461, 6), (160461,)) . # helper function for calculating ND*I indices (bands in the final dimension) def band_index(arr, a, b): return np.expand_dims((arr[..., a] - arr[..., b]) / (arr[..., a] + arr[..., b]), axis=1) ndvi = band_index(X, 3, 2) ndwi = band_index(X, 1, 3) X = np.concatenate([X, ndvi, ndwi], axis=1) X.shape . (160461, 8) . # split the data into test and train sets X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) . # calculate class weights to allow for training on inbalanced training samples labels, counts = np.unique(y_train, return_counts=True) class_weight_dict = dict(zip(labels, 1 / counts)) class_weight_dict . {0: 0.00046882325363338024, 1: 0.001597444089456869, 2: 0.0004928536224741252, 3: 1.970093973482535e-05, 4: 0.000819000819000819, 5: 1.5704257424187697e-05, 6: 0.0002473410833539451, 7: 0.0002824858757062147, 8: 0.05263157894736842, 9: 0.003115264797507788} . # initialize a RandomForestClassifier clf = RandomForestClassifier( n_estimators=200, class_weight=class_weight_dict, max_depth=6, n_jobs=-1, verbose=1, random_state=0) . # fit the model to the data (training) clf.fit(X, y) . [Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers. [Parallel(n_jobs=-1)]: Done 46 tasks | elapsed: 5.3s [Parallel(n_jobs=-1)]: Done 196 tasks | elapsed: 22.1s [Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed: 22.6s finished . RandomForestClassifier(bootstrap=True, class_weight={0: 0.00046882325363338024, 1: 0.001597444089456869, 2: 0.0004928536224741252, 3: 1.970093973482535e-05, 4: 0.000819000819000819, 5: 1.5704257424187697e-05, 6: 0.0002473410833539451, 7: 0.0002824858757062147, 8: 0.05263157894736842, 9: 0.003115264797507788}, criterion=&#39;gini&#39;, max_depth=6, max_features=&#39;auto&#39;, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1, oob_score=False, random_state=0, verbose=1, warm_start=False) . # predict on X_test to evaluate the model preds = clf.predict(X_test) cm = confusion_matrix(y_test, preds, labels=labels) . [Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers. [Parallel(n_jobs=2)]: Done 46 tasks | elapsed: 0.1s [Parallel(n_jobs=2)]: Done 196 tasks | elapsed: 0.5s [Parallel(n_jobs=2)]: Done 200 out of 200 | elapsed: 0.5s finished . # (optional) save the trained model as pickle file model_name = &#39;random_forest.sav&#39; with open(model_name, &#39;wb&#39;) as modelfile: pickle.dump(clf, modelfile) . # plot the confusion matrix %matplotlib inline cm = cm.astype(&#39;float&#39;) / cm.sum(axis=1)[:, np.newaxis] fig, ax = plt.subplots(figsize=(10, 10)) im = ax.imshow(cm, interpolation=&#39;nearest&#39;, cmap=plt.cm.Blues) ax.figure.colorbar(im, ax=ax) # We want to show all ticks... ax.set(xticks=np.arange(cm.shape[1]), yticks=np.arange(cm.shape[0]), # ... and label them with the respective list entries xticklabels=classes, yticklabels=classes, title=&#39;Normalized Confusion Matrix&#39;, ylabel=&#39;True label&#39;, xlabel=&#39;Predicted label&#39;) # Rotate the tick labels and set their alignment. plt.setp(ax.get_xticklabels(), rotation=45, ha=&quot;right&quot;, rotation_mode=&quot;anchor&quot;) # Loop over data dimensions and create text annotations. fmt = &#39;.2f&#39; thresh = cm.max() / 2. for i in range(cm.shape[0]): for j in range(cm.shape[1]): ax.text(j, i, format(cm[i, j], fmt), ha=&quot;center&quot;, va=&quot;center&quot;, color=&quot;white&quot; if cm[i, j] &gt; thresh else &quot;black&quot;) fig.tight_layout() . # predict again with the tree interpreter to see how much each band contributes to the classification sample = 100 prediction, bias, contributions = ti.predict(clf, X_test[:sample]) c = np.sum(contributions, axis=0) . # plot the contributions band_names = [&#39;Blue&#39;, &#39;Green&#39;, &#39;Red&#39;, &#39;NIR&#39;, &#39;SWIR1&#39;, &#39;SWIR2&#39;, &#39;NDVI&#39;, &#39;NDWI&#39;] gdf = gpd.GeoDataFrame(c, columns=classes, index=band_names) gdf.style.background_gradient(cmap=&#39;viridis&#39;) . Built Cloud Fallow Forestland Grassland Maize Shadow Sugarcane Sunflower Waterbody . Blue -0.708147 | -0.450384 | -2.68955 | 5.93931 | -0.460897 | 0.36023 | -0.154207 | -0.481766 | -0.167871 | -1.18672 | . Green -1.09678 | -0.00350109 | -1.57525 | 2.95823 | -0.336196 | 1.36762 | 0.551725 | -0.218106 | -0.732232 | -0.915498 | . Red -1.90573 | -0.59379 | 0.277761 | 3.01317 | 0.223731 | 0.7112 | -0.249443 | -0.619405 | -0.683663 | -0.173831 | . NIR 0.0684765 | -0.196796 | -2.96226 | 2.66494 | -0.747003 | 1.36166 | 0.791034 | 0.479715 | -1.19875 | -0.261016 | . SWIR1 0.166388 | 0.0139419 | -1.05339 | 3.05759 | -0.538389 | 0.81744 | 0.452637 | 0.357217 | -0.771856 | -2.50158 | . SWIR2 -0.734541 | -0.460321 | 0.715332 | 2.85215 | -0.179285 | 0.235555 | -0.271136 | -0.406578 | -1.01603 | -0.735149 | . NDVI -0.919315 | -0.238332 | 2.18171 | 3.64759 | -0.992437 | 1.17432 | -0.263332 | -0.444098 | -2.37513 | -1.77098 | . NDWI 0.121986 | 0.0502156 | 0.987004 | 2.8981 | -1.07648 | 0.740517 | 0.576891 | -0.444139 | -2.01388 | -1.84022 | . Generate predictions over the full image . Using the trained RandomForestClassifier clf over a new satellite image that cover a larger geospatial location. . # in this case, we predict over the entire input image # (only small portions were used for training) new_image = raster_file output_image = &quot;classification.tif&quot; with rasterio.open(new_image, &#39;r&#39;) as src: profile = src.profile profile.update( dtype=rasterio.uint8, count=1, ) with rasterio.open(output_image, &#39;w&#39;, **profile) as dst: # perform prediction on each small image patch to minimize required memory patch_size = 500 for i in range((src.shape[0] // patch_size) + 1): for j in range((src.shape[1] // patch_size) + 1): # define the pixels to read (and write) with rasterio windows reading window = rasterio.windows.Window( j * patch_size, i * patch_size, # don&#39;t read past the image bounds min(patch_size, src.shape[1] - j * patch_size), min(patch_size, src.shape[0] - i * patch_size)) # read the image into the proper format data = src.read(window=window) # adding indices if necessary img_swp = np.moveaxis(data, 0, 2) img_flat = img_swp.reshape(-1, img_swp.shape[-1]) img_ndvi = norm_inds(img_flat, 3, 2) img_ndwi = norm_inds(img_flat, 1, 3) img_w_ind = np.concatenate([img_flat, img_ndvi, img_ndwi], axis=1) # remove no data values, store the indices for later use m = np.ma.masked_invalid(img_w_ind) to_predict = img_w_ind[~m.mask].reshape(-1, img_w_ind.shape[-1]) # skip empty inputs if not len(to_predict): continue # predict img_preds = clf.predict(to_predict) # add the prediction back to the valid pixels (using only the first band of the mask to decide on validity) # makes the assumption that all bands have identical no-data value arrangements output = np.zeros(img_flat.shape[0]) output[~m.mask[:, 0]] = img_preds.flatten() # resize to the original image dimensions output = output.reshape(*img_swp.shape[:-1]) # create our final mask mask = (~m.mask[:, 0]).reshape(*img_swp.shape[:-1]) # write to the final files dst.write(output.astype(rasterio.uint8), 1, window=window) dst.write_mask(mask, window=window) .",
            "url": "https://developmentseed.github.io/sat-ml-training/2020/02/23/Randomforest_cropmapping_with_COGs.html",
            "relUrl": "/2020/02/23/Randomforest_cropmapping_with_COGs.html",
            "date": " • Feb 23, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Machine learning (ML)",
            "content": "How to navigate this guide . The order below should navigate the reader progressively through the topics that we will cover in the tutorials. The first section (1.2.0) is intended to build an understanding of machine learning fundamentals which will inform the following sections. Read the main links to articles, view/read but no need to try the code implementation examples, and for further learning - please see the references listed at the end. . 1.2.0 General Machine Learning Best Practices . What is Machine Learning? | About Train, Validation and Test Sets in Machine Learning | Handling imbalanced datasets in machine learning | Model Optimization read Abstract and section II (first two paragraphs) | Parallel and Distributed Deep Learning read sections 1.2, 2, 3 | Metrics to Evaluate your Machine Learning Algorithm | . 1.2.1 Classic Machine Learning (ML) . RandomForest . Random Forest Simple Explanation read sections: (1) Decision Tree: The Building Block and (2) From Decision Tree to Random Forest | Decision tree and RandomForest classifier in-depth for generic coding implementations . | w/ sciki-learn for the specific function . | RandomForest classifier in LULC case (Development Seed example) | . LightGBM . LightGBM: A Highly Efficient Gradient Boosting Decision Tree read Introduction and section 2.1 | LightGBM python library this is the library that we will use in the tutorial . | LightGBM in crop type mapping case (Development Seed example and SentinelHub eo-learn example) . | . 1.2.2 Deep learning . Deep Learning vs Classical Machine Learning . Deep Learning in a Nutshell – what it is, how it works, why care? read sections (1) What is Machine Learning? and (2) A First Look at Neural Networks | . Semantic Segmentation . Semantic Segmentation with Deep Learning | . TF dynamic UNet . UNet read sections 1 and 2 | Dynamic UNet in LULC case (Development Seed example) | . References: . Introduction to Statistical Learning book and examples written in python notebooks | Additional Examples from Python for Data Science | .",
            "url": "https://developmentseed.github.io/sat-ml-training/python/background/2020/02/23/IntroMachineLearning.html",
            "relUrl": "/python/background/2020/02/23/IntroMachineLearning.html",
            "date": " • Feb 23, 2020"
        }
        
    
  
    
        ,"post4": {
            "title": "Random Forest Model for Crop Type and Land Classification",
            "content": "This notebook teaches you how to read satellite imagery (Sentinal-2) from Google Earth Engine and use it for crop type mapping with a RandomForest Classifier. . If you want to run this whole notebook on Google Colab, here is the link. . | If you would like to replicate the workflow with the same data on your local machine, please download the data from our shared Google Drive folder. . | . Besides mapping crop type with RandomForestClassifier, we also prepared notebooks that use LightGBM and SVM. . Find our notebook for LightGBM on Google Colab; | Find our notebook for SVM on Google Colab. | . from os import path as op import pickle import geopandas as gpd import matplotlib.pyplot as plt import numpy as np import rasterio from rasterio.features import rasterize from rasterstats.io import bounds_window import rasterstats from sklearn.metrics import confusion_matrix from sklearn.model_selection import train_test_split from sklearn.ensemble import RandomForestClassifier from treeinterpreter import treeinterpreter as ti . Label data preparation . TODOs . Add training dataset sourcing, creations . # read in training data polygons that created as geojson training_vectors = gpd.read_file(&#39;training_data.geojson&#39;) training_vectors.head() . name description geometry . 0 Shadow | None | MULTIPOLYGON (((34.83383 1.18204, 34.83577 1.1... | . 1 Forestland | None | MULTIPOLYGON (((35.30961 1.01328, 35.30964 1.0... | . 2 Maize | early reproductive | MULTIPOLYGON (((34.90904 1.09515, 34.90907 1.0... | . 3 Sugarcane | no change..maize farm on the right and far lef... | MULTIPOLYGON (((34.90750 1.08934, 34.90753 1.0... | . 4 Maize | reproductive good crop | MULTIPOLYGON (((34.87144 0.82953, 34.87147 0.8... | . Reading image from GEE . TODOs How to read Sentinel-2 from GEE . raster_file = &#39;/Trans_nzoia_2019_05-02.tif&#39; . Model training . # find all unique values of training data names to use as classes classes = np.unique(training_vectors.name) classes . array([&#39;Built&#39;, &#39;Cloud&#39;, &#39;Fallow&#39;, &#39;Forestland&#39;, &#39;Grassland&#39;, &#39;Maize&#39;, &#39;Shadow&#39;, &#39;Sugarcane&#39;, &#39;Sunflower&#39;, &#39;Waterbody&#39;], dtype=object) . # create a dictionary to convert class names into integers for modeling class_dict = dict(zip(classes, range(len(classes)))) class_dict . {&#39;Built&#39;: 0, &#39;Cloud&#39;: 1, &#39;Fallow&#39;: 2, &#39;Forestland&#39;: 3, &#39;Grassland&#39;: 4, &#39;Maize&#39;: 5, &#39;Shadow&#39;: 6, &#39;Sugarcane&#39;: 7, &#39;Sunflower&#39;: 8, &#39;Waterbody&#39;: 9} . # raster information # a custom function for getting each value from the raster def all_values(x): return x # this larger cell reads data from a raster file for each training vector X_raw = [] y_raw = [] with rasterio.open(raster_file, &#39;r&#39;) as src: for (label, geom) in zip(training_vectors.name, training_vectors.geometry): # read the raster data matching the geometry bounds window = bounds_window(geom.bounds, src.transform) # store our window information window_affine = src.window_transform(window) fsrc = src.read(window=window) # rasterize the geometry into the larger shape and affine mask = rasterize( [(geom, 1)], out_shape=fsrc.shape[1:], transform=window_affine, fill=0, dtype=&#39;uint8&#39;, all_touched=True ).astype(bool) # for each label pixel (places where the mask is true) label_pixels = np.argwhere(mask) for (row, col) in label_pixels: # add a pixel of data to X data = fsrc[:,row,col] one_x = np.nan_to_num(data, nan=1e-3) X_raw.append(one_x) # add the label to y y_raw.append(class_dict[label]) . # convert the training data lists into the appropriate numpy array shape and format for scikit-learn X = np.array(X_raw) y = np.array(y_raw) (X.shape, y.shape) . ((160461, 6), (160461,)) . # helper function for calculating ND*I indices (bands in the final dimension) def band_index(arr, a, b): return np.expand_dims((arr[..., a] - arr[..., b]) / (arr[..., a] + arr[..., b]), axis=1) ndvi = band_index(X, 3, 2) ndwi = band_index(X, 1, 3) X = np.concatenate([X, ndvi, ndwi], axis=1) X.shape . (160461, 8) . # split the data into test and train sets X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) . # calculate class weights to allow for training on inbalanced training samples labels, counts = np.unique(y_train, return_counts=True) class_weight_dict = dict(zip(labels, 1 / counts)) class_weight_dict . {0: 0.00046882325363338024, 1: 0.001597444089456869, 2: 0.0004928536224741252, 3: 1.970093973482535e-05, 4: 0.000819000819000819, 5: 1.5704257424187697e-05, 6: 0.0002473410833539451, 7: 0.0002824858757062147, 8: 0.05263157894736842, 9: 0.003115264797507788} . # initialize a RandomForestClassifier clf = RandomForestClassifier( n_estimators=200, class_weight=class_weight_dict, max_depth=6, n_jobs=-1, verbose=1, random_state=0) . # fit the model to the data (training) clf.fit(X, y) . [Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers. [Parallel(n_jobs=-1)]: Done 46 tasks | elapsed: 5.3s [Parallel(n_jobs=-1)]: Done 196 tasks | elapsed: 22.1s [Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed: 22.6s finished . RandomForestClassifier(bootstrap=True, class_weight={0: 0.00046882325363338024, 1: 0.001597444089456869, 2: 0.0004928536224741252, 3: 1.970093973482535e-05, 4: 0.000819000819000819, 5: 1.5704257424187697e-05, 6: 0.0002473410833539451, 7: 0.0002824858757062147, 8: 0.05263157894736842, 9: 0.003115264797507788}, criterion=&#39;gini&#39;, max_depth=6, max_features=&#39;auto&#39;, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=-1, oob_score=False, random_state=0, verbose=1, warm_start=False) . # predict on X_test to evaluate the model preds = clf.predict(X_test) cm = confusion_matrix(y_test, preds, labels=labels) . [Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers. [Parallel(n_jobs=2)]: Done 46 tasks | elapsed: 0.1s [Parallel(n_jobs=2)]: Done 196 tasks | elapsed: 0.5s [Parallel(n_jobs=2)]: Done 200 out of 200 | elapsed: 0.5s finished . # (optional) save the trained model as pickle file model_name = &#39;random_forest.sav&#39; with open(model_name, &#39;wb&#39;) as modelfile: pickle.dump(clf, modelfile) . # plot the confusion matrix %matplotlib inline cm = cm.astype(&#39;float&#39;) / cm.sum(axis=1)[:, np.newaxis] fig, ax = plt.subplots(figsize=(10, 10)) im = ax.imshow(cm, interpolation=&#39;nearest&#39;, cmap=plt.cm.Blues) ax.figure.colorbar(im, ax=ax) # We want to show all ticks... ax.set(xticks=np.arange(cm.shape[1]), yticks=np.arange(cm.shape[0]), # ... and label them with the respective list entries xticklabels=classes, yticklabels=classes, title=&#39;Normalized Confusion Matrix&#39;, ylabel=&#39;True label&#39;, xlabel=&#39;Predicted label&#39;) # Rotate the tick labels and set their alignment. plt.setp(ax.get_xticklabels(), rotation=45, ha=&quot;right&quot;, rotation_mode=&quot;anchor&quot;) # Loop over data dimensions and create text annotations. fmt = &#39;.2f&#39; thresh = cm.max() / 2. for i in range(cm.shape[0]): for j in range(cm.shape[1]): ax.text(j, i, format(cm[i, j], fmt), ha=&quot;center&quot;, va=&quot;center&quot;, color=&quot;white&quot; if cm[i, j] &gt; thresh else &quot;black&quot;) fig.tight_layout() . # predict again with the tree interpreter to see how much each band contributes to the classification sample = 100 prediction, bias, contributions = ti.predict(clf, X_test[:sample]) c = np.sum(contributions, axis=0) . # plot the contributions band_names = [&#39;Blue&#39;, &#39;Green&#39;, &#39;Red&#39;, &#39;NIR&#39;, &#39;SWIR1&#39;, &#39;SWIR2&#39;, &#39;NDVI&#39;, &#39;NDWI&#39;] gdf = gpd.GeoDataFrame(c, columns=classes, index=band_names) gdf.style.background_gradient(cmap=&#39;viridis&#39;) . Built Cloud Fallow Forestland Grassland Maize Shadow Sugarcane Sunflower Waterbody . Blue -0.708147 | -0.450384 | -2.68955 | 5.93931 | -0.460897 | 0.36023 | -0.154207 | -0.481766 | -0.167871 | -1.18672 | . Green -1.09678 | -0.00350109 | -1.57525 | 2.95823 | -0.336196 | 1.36762 | 0.551725 | -0.218106 | -0.732232 | -0.915498 | . Red -1.90573 | -0.59379 | 0.277761 | 3.01317 | 0.223731 | 0.7112 | -0.249443 | -0.619405 | -0.683663 | -0.173831 | . NIR 0.0684765 | -0.196796 | -2.96226 | 2.66494 | -0.747003 | 1.36166 | 0.791034 | 0.479715 | -1.19875 | -0.261016 | . SWIR1 0.166388 | 0.0139419 | -1.05339 | 3.05759 | -0.538389 | 0.81744 | 0.452637 | 0.357217 | -0.771856 | -2.50158 | . SWIR2 -0.734541 | -0.460321 | 0.715332 | 2.85215 | -0.179285 | 0.235555 | -0.271136 | -0.406578 | -1.01603 | -0.735149 | . NDVI -0.919315 | -0.238332 | 2.18171 | 3.64759 | -0.992437 | 1.17432 | -0.263332 | -0.444098 | -2.37513 | -1.77098 | . NDWI 0.121986 | 0.0502156 | 0.987004 | 2.8981 | -1.07648 | 0.740517 | 0.576891 | -0.444139 | -2.01388 | -1.84022 | . Generate predictions over the full image . Using the trained RandomForestClassifier clf over a new satellite image that cover a larger geospatial location. . # in this case, we predict over the entire input image # (only small portions were used for training) new_image = raster_file output_image = &quot;classification.tif&quot; with rasterio.open(new_image, &#39;r&#39;) as src: profile = src.profile profile.update( dtype=rasterio.uint8, count=1, ) with rasterio.open(output_image, &#39;w&#39;, **profile) as dst: # perform prediction on each small image patch to minimize required memory patch_size = 500 for i in range((src.shape[0] // patch_size) + 1): for j in range((src.shape[1] // patch_size) + 1): # define the pixels to read (and write) with rasterio windows reading window = rasterio.windows.Window( j * patch_size, i * patch_size, # don&#39;t read past the image bounds min(patch_size, src.shape[1] - j * patch_size), min(patch_size, src.shape[0] - i * patch_size)) # read the image into the proper format data = src.read(window=window) # adding indices if necessary img_swp = np.moveaxis(data, 0, 2) img_flat = img_swp.reshape(-1, img_swp.shape[-1]) img_ndvi = norm_inds(img_flat, 3, 2) img_ndwi = norm_inds(img_flat, 1, 3) img_w_ind = np.concatenate([img_flat, img_ndvi, img_ndwi], axis=1) # remove no data values, store the indices for later use m = np.ma.masked_invalid(img_w_ind) to_predict = img_w_ind[~m.mask].reshape(-1, img_w_ind.shape[-1]) # skip empty inputs if not len(to_predict): continue # predict img_preds = clf.predict(to_predict) # add the prediction back to the valid pixels (using only the first band of the mask to decide on validity) # makes the assumption that all bands have identical no-data value arrangements output = np.zeros(img_flat.shape[0]) output[~m.mask[:, 0]] = img_preds.flatten() # resize to the original image dimensions output = output.reshape(*img_swp.shape[:-1]) # create our final mask mask = (~m.mask[:, 0]).reshape(*img_swp.shape[:-1]) # write to the final files dst.write(output.astype(rasterio.uint8), 1, window=window) dst.write_mask(mask, window=window) .",
            "url": "https://developmentseed.github.io/sat-ml-training/2020/02/22/Randomforest_cropmapping-with_GEE.html",
            "relUrl": "/2020/02/22/Randomforest_cropmapping-with_GEE.html",
            "date": " • Feb 22, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "Geospatial Python",
            "content": "The following material covers the basics of using spatial data in python. The main goal is to become familiar with the libraries used, and to try a few examples of operations with vector, and raster data, including some basic visualizations. . Vector Data . . Note: A GeoDataFrame is a pandas DataFrame with geometries (GeoSeries) . How to load and save spatial data with Geopandas | General Data Manipulation (Geopandas) | Subsetting by Attributes, to select records based on attributes use the techniques from Pandas | Projections | Intersects lab_03.html#Spatial-manipulations) | Spatial Join | Spatial Aggregation | Derive Centroids | Bounding Box For each row in a GeoDataFrame GeoSeries.bounds if you want to extract the coordinates. | For each row in a GeoDataFrame if you want another geodataframe you can do spatial operations with GeoSeries.envelope | For a whole GeoDataFrame GeoSeries.total_bounds | . | . import geopandas url = &quot;https://d2ad6b4ur7yvpq.cloudfront.net/naturalearth-3.3.0/ne_110m_admin_0_countries.geojson&quot; countries_gdf = geopandas.read_file(url) print(countries_gdf.head()) . scalerank labelrank sovereignt sov_a3 adm0_dif level 0 1 3 Afghanistan AFG 0 2 1 1 3 Angola AGO 0 2 2 1 6 Albania ALB 0 2 3 1 4 United Arab Emirates ARE 0 2 4 1 2 Argentina ARG 0 2 type admin adm0_a3 geou_dif ... region_un 0 Sovereign country Afghanistan AFG 0 ... Asia 1 Sovereign country Angola AGO 0 ... Africa 2 Sovereign country Albania ALB 0 ... Europe 3 Sovereign country United Arab Emirates ARE 0 ... Asia 4 Sovereign country Argentina ARG 0 ... Americas subregion region_wb name_len long_len abbrev_len 0 Southern Asia South Asia 11 11 4 1 Middle Africa Sub-Saharan Africa 6 6 4 2 Southern Europe Europe &amp; Central Asia 7 7 4 3 Western Asia Middle East &amp; North Africa 20 20 6 4 South America Latin America &amp; Caribbean 9 9 4 tiny homepart featureclass 0 -99 1 Admin-0 country 1 -99 1 Admin-0 country 2 -99 1 Admin-0 country 3 -99 1 Admin-0 country 4 -99 1 Admin-0 country geometry 0 POLYGON ((61.21082 35.65007, 62.23065 35.27066... 1 MULTIPOLYGON (((16.32653 -5.87747, 16.57318 -6... 2 POLYGON ((20.59025 41.85540, 20.46318 41.51509... 3 POLYGON ((51.57952 24.24550, 51.75744 24.29407... 4 MULTIPOLYGON (((-65.50000 -55.20000, -66.45000... [5 rows x 64 columns] . countries_gdf.total_bounds . [-180. -90. 180. 83.64513] . countries_gdf.head().bounds . minx miny maxx maxy 0 60.528430 29.318572 75.158028 38.486282 1 11.640096 -17.930636 24.079905 -4.438023 2 19.304486 39.624998 21.020040 42.688247 3 51.579519 22.496948 56.396847 26.055464 4 -73.415436 -55.250000 -53.628349 -21.832310 . countries_gdf.head().envelope . 0 POLYGON ((60.52843 29.31857, 75.15803 29.31857... 1 POLYGON ((11.64010 -17.93064, 24.07991 -17.930... 2 POLYGON ((19.30449 39.62500, 21.02004 39.62500... 3 POLYGON ((51.57952 22.49695, 56.39685 22.49695... 4 POLYGON ((-73.41544 -55.25000, -53.62835 -55.2... dtype: geometry . Making Maps . Static, more examples | Dynamic maps using Folium | . Optional Bonus Material . Advanced Vector Input/Output(I/O) with Fiona | Using Spatial Indexes for faster spatial operations | . Raster . How to load and save data . Rasterio (Reading) | Rasterio (Writing). The recommended default writing Profile is a Cloud Optimized Geotiff, as shown with the rio-cogeo library. | . | Numpy Arrays (Rasters) . Clipping raster by AOI | Band Math (aka Map Algebra) | Sampling data (extract) from raster with a vector | . | . Making Maps . Static | Dynamic with Vector and Raster Data in Folium | . Additional References . The majority of lessons come from . AutoGIS | EarthLab | . Each Library has it&#39;s own great documentation . Geopandas for vector geometry and attribute handling | Shapely for vector geometry operations that Geopandas doesn’t do. Geopandas actually imports Shapely for most operations. | Rasterio | rio-cogeo | folium | .",
            "url": "https://developmentseed.github.io/sat-ml-training/python/background/2020/02/22/GeospatialPython.html",
            "relUrl": "/python/background/2020/02/22/GeospatialPython.html",
            "date": " • Feb 22, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "Intro to Python",
            "content": "General python . In this section we review the fundamentals of using the Python programming language with a focus on being able to use python for geospatial data science with machine learning. Based on the list of goals, and your prior experience select from the list of tutorials. Feel free to do as many as you like, and skim lightly if you are already familiar with the topics. . For local practice you can install and user the Python with Conda, we recommend coding in a Jupyter Notebook which is similar to the Google Colab online editor that will be used in the other tutorials on this site. . Goals . Data types . Basic Types: Integers (Whole numbers), Floats (Numbers with decimals), Strings | Constructed Types: Lists, Dictionaries . Note: Python Dictionaries and JSON files very similar. | . | Looping (Program flow control) . Using looping to iterate over a set of items to repeat a process . Example: Loop over a list of items . | Example: Loop over list of files . | . | . | Calling functions . Importing libraries (aka modules, packages) | How to call a function | How to write a small function | . | . Lessons . Pick from the following lessons. We recommend at least 1, and if you choose to watch the videos then we suggest you also do some of the Interactive coding examples from the other options. Trying some code is one of the best ways to learn. . An introduction or refresher for Python 3 Online Videos from Udemy | Interactive lessons with examples and quizzes from CodeAcademy. All lessons except #10 on Classes (optional) | Demonstration Notebooks that Accompany the Whirlwind Tour Of Python Book (Available for free). Lessons 1-9, everything else is optional. | Additional References . Python Documentation https://docs.python.org/3/tutorial/index.html . | More tutorials https://docs.python-guide.org/intro/learning/ . | . Python for Data Science . In this section we specifically review Python for Data Science, focusing on the main data structures used to manipulate data, numpy arrays and pandas dataframes. Each link is a tutorial or example that you can try. . Numpy Arrays . . Important: Understanding multidimensional data arrays as a data structure. . Note: Numpy array data must all be of the same type (e.g. Integer, Float, etc…) . Lessons: . Introduction to NumPy . | Understanding Data Types in Python . | The Basics of NumPy Arrays . | Computation on NumPy Arrays: Universal Functions . | Aggregations: Min, Max, and Everything In Between . | . Pandas DataFrames . . Important: Understanding data frames as a table (sheet), with data records as rows, and data attributes as columns. Each column can be a different data type. . Lessons: . Introduction . | Importing and exporting CSV and JSON data sources . | Summarizing (aggregating) data . | Selecting relevant data records . | All in one . | (Optional) Further Reading and Materials . | . References . Primary Source PythonDataScienceHandbook | Secondary Source Datacarpentry python-ecology-lesson | . Plotting . . Important: Being able to visualize selections of data in a variety of standard plot types. Histogram, Bar, Line, Scatter Plot (XY) . Visualization with Matplotlib . | Simple Line Plots . | Scatter Plots . | Density and Contour Plots . | Histograms, Binnings, and Density . | .",
            "url": "https://developmentseed.github.io/sat-ml-training/python/background/2020/02/21/IntroPython.html",
            "relUrl": "/python/background/2020/02/21/IntroPython.html",
            "date": " • Feb 21, 2020"
        }
        
    
  
    
        ,"post7": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: main- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . #collapse-hide import pandas as pd import altair as alt . . ModuleNotFoundError Traceback (most recent call last) &lt;ipython-input-2-88b922e30289&gt; in &lt;module&gt; 1 #collapse-hide 2 import pandas as pd -&gt; 3 import altair as alt ModuleNotFoundError: No module named &#39;altair&#39; . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . #collapse-show cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # single-value selection over [Major_Genre, MPAA_Rating] pairs # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . # select a point for which to provide details-on-demand label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . # display table with pandas df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://developmentseed.github.io/sat-ml-training/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Material on this website is available under __ license. It was originally developed by Development Seed for the SERVIR program (NASA &amp; USAID). . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://developmentseed.github.io/sat-ml-training/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://developmentseed.github.io/sat-ml-training/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}